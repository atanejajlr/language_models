<html>
<head>
  <title>Convolutions: Hand engineered solutions to neural networks built from large data</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img src="https://media.licdn.com/mediaC5112AQE2oUE0ZKx7_g" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/convolutions-hand-engineered-solutions-neural-networks-ajay-taneja">Convolutions: Hand engineered solutions to neural networks built from large data</a></h1>
    <p class="created">Created on 2020-02-29 12:33</p>
  <p class="published">Published on 2020-02-29 12:50</p>
  <div><p>[With due thanks to the course on "Convolutional Neural Networks" in the Deep Learning Specialization and discussions in the group forum]</p><p>Convolution existed as a technique in digital signal processing long before the rise of neural networks that can learn filter weights from training data. In those days, filter weights were determined by trial and error. This is how people figured out that [-1 0 1] works as a generic edge detector, for example.</p><p>People with&nbsp;experience in&nbsp;building predictive models in the clinical (healthcare) domain state that initially,&nbsp;they decided which attributes to include in the models based on recommendations from doctors, which was based on their instinct, experience and traditional medical schooling.&nbsp;It turned&nbsp;out that weren't always the best or most predictive dimensions to use - just the ones they could manage in their heads or in spreadsheets.</p><p>In the absence of large datasets or algorithms and hardware to efficiently process them,&nbsp;they ended up using instinct or human-built sets of values. They'd take small existing data sets and copy them with slight modifications, flip an image horizontally, for example, or introducing some noise or jitter into a data set. But these 'hand-engineered' solutions turned out to be more expensive in time and&nbsp;money to build and validate, and not as useful or generalizable as algorithms and filter-weights informed by lots of real data. In&nbsp;the healthcare work, the data-driven models always outperformed the hand built ones if&nbsp;they had enough clean data.</p></div>
</body>
</html>